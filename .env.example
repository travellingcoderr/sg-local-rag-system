# Copy to .env and fill in. .env is gitignored.

# -----------------------------------------------------------------------------
# LLM (choose one for local vs prod)
# -----------------------------------------------------------------------------
# Local (Docker): use ollama + OLLAMA_HOST=http://ollama:11434 in docker-compose
# Prod: set LLM_PROVIDER=openai or gemini and the corresponding API key.
LLM_PROVIDER=ollama
OLLAMA_MODEL_NAME=llama3.2:1b
OLLAMA_HOST=http://localhost:11434

# OpenAI (prod)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Google Gemini (prod)
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash

# -----------------------------------------------------------------------------
# Optional overrides
# -----------------------------------------------------------------------------
# OPENSEARCH_HOST=localhost
# OPENSEARCH_PORT=9200
# EMBEDDING_MODEL_PATH=embedding_model
# EMBEDDING_DIMENSION=768
